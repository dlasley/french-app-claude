/**
 * Controller script for the content regeneration pipeline
 *
 * Orchestrates:
 * 1. PDF â†’ Markdown conversion (convert-pdfs.ts logic)
 * 2. Topic extraction & validation (suggest-unit-topics.ts logic)
 * 3. Question generation (generate-questions.ts)
 *
 * Usage:
 *   npx tsx scripts/regenerate.ts <unit-id> [options]
 *   npx tsx scripts/regenerate.ts --all [options]
 *
 * Options:
 *   --review-topics Enable interactive topic review (for expert users)
 *   --skip-convert  Skip PDF conversion (use existing markdown)
 *   --skip-topics   Skip topic extraction (use existing topics in units.ts)
 *   --write-db      Sync generated questions to Supabase
 *   --sync-db       (deprecated alias for --write-db)
 *   --audit         Run quality audit after generation (requires --write-db)
 *   --dry-run       Show what would be done without executing
 *
 * Examples:
 *   npx tsx scripts/regenerate.ts unit-4
 *   npx tsx scripts/regenerate.ts unit-4 --write-db
 *   npx tsx scripts/regenerate.ts unit-4 --write-db --audit
 *   npx tsx scripts/regenerate.ts unit-4 --skip-convert
 *   npx tsx scripts/regenerate.ts --all --write-db
 */

import { config } from 'dotenv';
config({ path: '.env.local' });

import Anthropic from '@anthropic-ai/sdk';
import { execSync, spawn } from 'child_process';
import fs from 'fs';
import path from 'path';
import readline from 'readline';
import { units } from '../src/lib/units';
import { insertUnitEntry } from './lib/file-updaters';
import { MODELS } from './lib/config';

// Initialize Anthropic client for PDF conversion
const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

// Directory paths
const PDF_DIR = path.join(process.cwd(), 'PDF');
const LEARNINGS_DIR = path.join(process.cwd(), 'learnings');

interface PipelineOptions {
  unitId: string | '--all';
  reviewTopics: boolean;
  skipConvert: boolean;
  forceConvert: boolean;
  skipTopics: boolean;
  syncDb: boolean;
  audit: boolean;
  dryRun: boolean;
}

// PDF to Markdown conversion prompt (same as convert-pdfs.ts)
const CONVERSION_PROMPT = `You are converting French language course materials from PDF to clean, structured markdown.

## Output Requirements

**CRITICAL - DO NOT include these artifacts:**
- No introductory commentary like "Here's the content..." or "I'll convert this..."
- No code fence wrappers (\`\`\`markdown ... \`\`\`)
- No concluding summaries like "This markdown preserves..." or "Perfect for..."
- No meta-commentary about the conversion process
- START IMMEDIATELY with the heading: # French I - [Unit Name]

## Structure Format

Use this exact structure:

# French I - [Unit Name]

## [Section Title]
[Content]

---

## Vocabulaire actif
- **french_word** - english_translation
- **un(e) Ã©lÃ¨ve** - a student

### Grammar Notes
[Explanations]

### RÃ©ponses (Answers)
1. Answer one
2. Answer two

---

## [Next Section]

## Formatting Rules

1. **Section Separators**: Use \`---\` between major sections
2. **Vocabulary Lists**: Use \`- **word** - translation\` format
3. **Numbered Lists**: Preserve from source (exercises, rules, etc.)
4. **YouTube Links**: Preserve as-is when present
5. **French-English Pairs**: Format as \`**French phrase** - English translation\`
6. **Grammar Tables**: Use markdown tables when appropriate
7. **Answer Keys**: Include under \`### RÃ©ponses\` subsections
8. **Headings**: Use ## for main sections, ### for subsections

## Content Preservation

MUST preserve:
- All French vocabulary with accents (Ã©, Ã¨, Ãª, Ã«, Ã , Ã¢, Ã¹, Ã», Ã´, Ã§, etc.)
- All answer keys and exercise solutions
- YouTube video links
- Grammar explanations and conjugation tables
- Cultural notes and context
- Activity instructions

DO NOT add:
- Your own commentary or observations
- Suggestions for teachers
- Quality assessments of the content
- Explanations of what the markdown is "good for"

Now convert the following PDF text content to clean markdown:

`;

/**
 * Extract text from PDF using pdftotext (from poppler)
 */
function extractPdfText(pdfPath: string): string {
  try {
    const result = execSync(`pdftotext "${pdfPath}" -`, {
      encoding: 'utf-8',
      maxBuffer: 50 * 1024 * 1024, // 50MB buffer
    });
    return result;
  } catch (error) {
    console.error(`  âŒ Error extracting text from ${path.basename(pdfPath)}:`, error);
    throw error;
  }
}

/**
 * Split pdftotext output into chunks using form feed page boundaries.
 * Groups pages so each chunk stays under maxCharsPerChunk.
 */
function chunkPdfText(pdfText: string, maxCharsPerChunk: number = 15000): string[] {
  // pdftotext inserts form feed (\f) between pages
  const pages = pdfText.split('\f').filter(p => p.trim().length > 0);

  if (pages.length === 0) return [pdfText];

  const chunks: string[] = [];
  let currentChunk = '';

  for (const page of pages) {
    if (currentChunk.length + page.length > maxCharsPerChunk && currentChunk.length > 0) {
      chunks.push(currentChunk.trim());
      currentChunk = '';
    }
    currentChunk += page + '\n\n';
  }

  if (currentChunk.trim().length > 0) {
    chunks.push(currentChunk.trim());
  }

  return chunks;
}

/**
 * Convert a single chunk of PDF text to markdown using Claude
 */
async function convertChunkToMarkdown(
  chunkText: string,
  pdfName: string,
  chunkIndex: number,
  totalChunks: number
): Promise<string> {
  const chunkContext = totalChunks > 1
    ? `\n\nNote: This is section ${chunkIndex + 1} of ${totalChunks} from ${pdfName}. Convert ALL content faithfully â€” do NOT summarize, skip exercises, or deduplicate. If a section continues from a previous chunk, just convert what you see.\n\n`
    : '\n\n';

  const message = await anthropic.messages.create({
    model: MODELS.pdfConversion,
    max_tokens: 16000,
    messages: [
      {
        role: 'user',
        content: CONVERSION_PROMPT + chunkContext + chunkText,
      },
    ],
  });

  const responseText = message.content[0].type === 'text' ? message.content[0].text : '';
  return cleanConversionArtifacts(responseText);
}

/**
 * Convert PDF text to markdown using Claude, chunking large inputs
 */
async function convertPdfToMarkdown(pdfText: string, pdfName: string): Promise<string> {
  const chunks = chunkPdfText(pdfText);

  if (chunks.length === 1) {
    console.log(`  ğŸ“ Sending ${pdfName} to Claude for conversion (1 chunk)...`);
    return convertChunkToMarkdown(chunks[0], pdfName, 0, 1);
  }

  console.log(`  ğŸ“ Sending ${pdfName} to Claude in ${chunks.length} chunks...`);
  const markdownParts: string[] = [];

  for (let i = 0; i < chunks.length; i++) {
    console.log(`     Chunk ${i + 1}/${chunks.length} (${chunks[i].length.toLocaleString()} chars)...`);
    const md = await convertChunkToMarkdown(chunks[i], pdfName, i, chunks.length);
    markdownParts.push(md);

    // Rate limit delay between chunks
    if (i < chunks.length - 1) {
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }

  return markdownParts.join('\n\n---\n\n');
}

/**
 * Clean common LLM artifacts from conversion output
 */
function cleanConversionArtifacts(text: string): string {
  let cleaned = text;

  // Remove opening code fence
  if (cleaned.startsWith('```markdown')) {
    cleaned = cleaned.replace(/^```markdown\n?/, '');
  }
  if (cleaned.startsWith('```')) {
    cleaned = cleaned.replace(/^```\n?/, '');
  }

  // Remove closing code fence
  if (cleaned.endsWith('```')) {
    cleaned = cleaned.replace(/\n?```$/, '');
  }

  // Remove introductory lines
  const introPatterns = [
    /^I'll convert this.*?\n+/i,
    /^Here's the.*?\n+/i,
    /^The PDF file.*?\n+/i,
    /^Perfect!.*?\n+/i,
    /^Now I'll.*?\n+/i,
  ];

  for (const pattern of introPatterns) {
    cleaned = cleaned.replace(pattern, '');
  }

  // Remove concluding summaries (after last ---)
  const lastSeparator = cleaned.lastIndexOf('\n---\n');
  if (lastSeparator !== -1) {
    const afterSeparator = cleaned.substring(lastSeparator + 5);
    if (
      afterSeparator.includes('This markdown preserves') ||
      afterSeparator.includes('Perfect for') ||
      afterSeparator.includes('The content above')
    ) {
      cleaned = cleaned.substring(0, lastSeparator + 5);
    }
  }

  return cleaned.trim();
}

/**
 * Check if pdftotext is available
 */
function checkPdftotext(): boolean {
  try {
    execSync('which pdftotext', { encoding: 'utf-8' });
    return true;
  } catch {
    return false;
  }
}

interface StepResult {
  success: boolean;
  output?: string;
  error?: string;
}

/**
 * Parse command line arguments
 */
function parseArgs(): PipelineOptions {
  const args = process.argv.slice(2);

  if (args.length === 0 || args[0] === '--help' || args[0] === '-h') {
    printUsage();
    process.exit(0);
  }

  // Handle --write-db (canonical) and --sync-db (deprecated alias)
  const hasSyncDb = args.includes('--sync-db');
  const hasWriteDb = args.includes('--write-db');
  if (hasSyncDb && !hasWriteDb) {
    console.warn('âš ï¸  --sync-db is deprecated, use --write-db instead');
  }

  const options: PipelineOptions = {
    unitId: args[0],
    reviewTopics: args.includes('--review-topics'),
    skipConvert: args.includes('--skip-convert'),
    forceConvert: args.includes('--force-convert'),
    skipTopics: args.includes('--skip-topics'),
    syncDb: hasWriteDb || hasSyncDb,
    audit: args.includes('--audit'),
    dryRun: args.includes('--dry-run'),
  };

  // Validate --audit requires --write-db
  if (options.audit && !options.syncDb) {
    console.error('âŒ --audit requires --write-db (questions must be in DB to audit)');
    process.exit(1);
  }

  return options;
}

function printUsage(): void {
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              CONTENT REGENERATION PIPELINE                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Usage:
  npx tsx scripts/regenerate.ts <unit-id> [options]
  npx tsx scripts/regenerate.ts --all [options]

Options:
  --review-topics Interactive topic review (for fluent French speakers only)
  --skip-convert  Skip PDF conversion (use existing markdown)
  --force-convert Force PDF reconversion even if markdown exists
  --skip-topics   Skip topic extraction (use existing topics in units.ts)
  --write-db      Sync generated questions to database
  --sync-db       (deprecated alias for --write-db)
  --audit         Run quality audit after generation (requires --write-db)
  --dry-run       Show what would be done without executing

Examples:
  npx tsx scripts/regenerate.ts unit-4                    # Full pipeline for unit-4
  npx tsx scripts/regenerate.ts unit-4 --write-db         # Generate and sync to DB
  npx tsx scripts/regenerate.ts unit-4 --write-db --audit # Generate, sync, and audit
  npx tsx scripts/regenerate.ts unit-4 --skip-convert --write-db
  npx tsx scripts/regenerate.ts --all --write-db          # Regenerate all units

Pipeline Steps:
  1. PDF â†’ Markdown    Convert PDF to structured markdown
  2. Topic Extraction  Extract and validate topics against units.ts
  3. Question Gen      Generate questions for each topic/difficulty
  4. Quality Audit     (optional, --audit) Promote pending â†’ active/flagged
  `);
}

/**
 * Prompt user for confirmation
 */
async function promptUser(question: string): Promise<boolean> {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  return new Promise((resolve) => {
    rl.question(`${question} (y/n): `, (answer) => {
      rl.close();
      resolve(answer.toLowerCase() === 'y' || answer.toLowerCase() === 'yes');
    });
  });
}

/**
 * Find all PDF files for a unit
 * Returns all PDFs matching the unit pattern (canonical first, then others)
 */
function findPdfsForUnit(unitId: string): string[] {
  const matches: string[] = [];

  if (!fs.existsSync(PDF_DIR)) {
    return matches;
  }

  const files = fs.readdirSync(PDF_DIR).filter(f => f.toLowerCase().endsWith('.pdf'));

  // Special case for 'introduction' unit
  if (unitId === 'introduction') {
    const pattern = /introduction/i;
    for (const file of files) {
      if (pattern.test(file)) {
        matches.push(path.join(PDF_DIR, file));
      }
    }
    // Sort with "French 1 Introduction.pdf" first
    matches.sort((a, b) => {
      const aIsCanonical = path.basename(a).toLowerCase() === 'french 1 introduction.pdf';
      const bIsCanonical = path.basename(b).toLowerCase() === 'french 1 introduction.pdf';
      if (aIsCanonical && !bIsCanonical) return -1;
      if (!aIsCanonical && bIsCanonical) return 1;
      return a.localeCompare(b);
    });
    return matches;
  }

  // Standard unit-N pattern handling
  const unitNum = unitId.replace('unit-', '');

  // Pattern requires unit number to be followed by non-digit (or end of string)
  // to avoid "unit 20" matching "unit 2"
  const pattern = new RegExp(`unit[\\s_-]?${unitNum}(?:\\D|$)`, 'i');

  // Sort: canonical first (French 1 Unit X.pdf), then others alphabetically
  const canonical = `French 1 Unit ${unitNum}.pdf`;

  for (const file of files) {
    if (pattern.test(file)) {
      matches.push(path.join(PDF_DIR, file));
    }
  }

  // Sort with canonical first
  matches.sort((a, b) => {
    const aIsCanonical = path.basename(a) === canonical;
    const bIsCanonical = path.basename(b) === canonical;
    if (aIsCanonical && !bIsCanonical) return -1;
    if (!aIsCanonical && bIsCanonical) return 1;
    return a.localeCompare(b);
  });

  return matches;
}

/**
 * Find markdown file for a unit
 * Searches for files containing "unit X" or "unit-X" (case-insensitive)
 * Throws on ambiguous matches, returns null if nothing found
 */
function findMarkdownForUnit(unitId: string): string | null {
  // Special case for 'introduction' unit
  if (unitId === 'introduction') {
    const explicitPaths = [
      path.join(LEARNINGS_DIR, 'French 1 Introduction.md'),
      path.join(LEARNINGS_DIR, 'introduction.md'),
    ];

    for (const p of explicitPaths) {
      if (fs.existsSync(p)) {
        return p;
      }
    }

    // Search for any .md file containing "introduction" in the filename
    const pattern = /introduction/i;
    const searchDirs = [LEARNINGS_DIR, path.join(LEARNINGS_DIR, 'test-conversions')];
    const matches: string[] = [];

    for (const dir of searchDirs) {
      if (!fs.existsSync(dir)) continue;
      const files = fs.readdirSync(dir).filter(f => f.endsWith('.md'));
      for (const file of files) {
        if (pattern.test(file)) {
          matches.push(path.join(dir, file));
        }
      }
    }

    if (matches.length === 1) {
      console.log(`  Found markdown via pattern match: ${matches[0]}`);
      return matches[0];
    }
    if (matches.length > 1) {
      console.error(`  Ambiguous: found ${matches.length} markdown files matching "introduction":`);
      for (const m of matches) {
        console.error(`     - ${m}`);
      }
      throw new Error('Ambiguous markdown files for introduction');
    }
    return null;
  }

  // Standard unit-N handling
  const unitNum = unitId.replace('unit-', '');

  // Priority 1: Check explicit paths first (no ambiguity possible)
  const explicitPaths = [
    path.join(LEARNINGS_DIR, `French 1 Unit ${unitNum}.md`),
    path.join(LEARNINGS_DIR, `unit-${unitNum}.md`),
    path.join(LEARNINGS_DIR, 'test-conversions', `unit-${unitNum}-test.md`),
  ];

  for (const p of explicitPaths) {
    if (fs.existsSync(p)) {
      return p;
    }
  }

  // Priority 2: Search for any .md file containing "unit X" or "unit-X" in the filename
  // Pattern requires unit number to be followed by non-digit (or end of string)
  // to avoid "unit 20" matching "unit 2"
  const pattern = new RegExp(`unit[\\s_-]?${unitNum}(?:\\D|$)`, 'i');

  const searchDirs = [LEARNINGS_DIR, path.join(LEARNINGS_DIR, 'test-conversions')];
  const matches: string[] = [];

  for (const dir of searchDirs) {
    if (!fs.existsSync(dir)) continue;

    const files = fs.readdirSync(dir).filter(f => f.endsWith('.md'));
    for (const file of files) {
      if (pattern.test(file)) {
        matches.push(path.join(dir, file));
      }
    }
  }

  if (matches.length === 0) {
    return null;
  }

  if (matches.length === 1) {
    console.log(`  ğŸ“„ Found markdown via pattern match: ${matches[0]}`);
    return matches[0];
  }

  // Multiple matches - ambiguous, report error
  console.error(`  âŒ Ambiguous: found ${matches.length} markdown files matching "${unitId}":`);
  for (const m of matches) {
    console.error(`     - ${m}`);
  }
  console.error(`  ğŸ’¡ Rename files or use explicit path with suggest-unit-topics.ts directly`);
  throw new Error(`Ambiguous markdown files for ${unitId}`);
}

/**
 * Run a script and capture output
 */
function runScript(command: string, args: string[], dryRun: boolean): StepResult {
  const fullCommand = `npx tsx ${command} ${args.join(' ')}`;

  if (dryRun) {
    console.log(`  [DRY RUN] Would execute: ${fullCommand}`);
    return { success: true, output: '[dry run - not executed]' };
  }

  try {
    const output = execSync(fullCommand, {
      encoding: 'utf-8',
      maxBuffer: 50 * 1024 * 1024,
      stdio: ['inherit', 'pipe', 'pipe'],
    });
    return { success: true, output };
  } catch (error: any) {
    return {
      success: false,
      error: error.message,
      output: error.stdout || error.stderr,
    };
  }
}

/**
 * Step 1: Convert PDFs to Markdown
 * Finds all PDFs for a unit and combines their markdown into one file
 * Auto-converts PDFs if markdown doesn't exist
 */
async function stepConvertPdf(
  unitId: string,
  options: PipelineOptions
): Promise<{ success: boolean; markdownPath?: string }> {
  console.log('\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
  console.log('â”‚  STEP 1: PDF â†’ Markdown Conversion                         â”‚');
  console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n');

  // Skip conversion entirely if requested
  if (options.skipConvert) {
    console.log('  â­ï¸  Skipping (--skip-convert)');
    const existingMd = findMarkdownForUnit(unitId);
    if (existingMd) {
      console.log(`  â„¹ï¸  Using existing: ${existingMd}`);
      return { success: true, markdownPath: existingMd };
    }
    console.log('  âŒ No existing markdown found');
    return { success: false };
  }

  const pdfPaths = findPdfsForUnit(unitId);

  // No PDFs found - fall back to existing markdown
  if (pdfPaths.length === 0) {
    console.log(`  âš ï¸  No PDFs found for ${unitId}`);
    const existingMd = findMarkdownForUnit(unitId);
    if (existingMd) {
      console.log(`  â„¹ï¸  Using existing markdown: ${existingMd}`);
      return { success: true, markdownPath: existingMd };
    }
    return { success: false };
  }

  console.log(`  ğŸ“„ Found ${pdfPaths.length} PDF(s) for ${unitId}:`);
  for (const p of pdfPaths) {
    console.log(`     - ${path.basename(p)}`);
  }

  // Combined output path
  const combinedOutput = unitId === 'introduction'
    ? path.join(LEARNINGS_DIR, 'French 1 Introduction.md')
    : path.join(LEARNINGS_DIR, `French 1 Unit ${unitId.replace('unit-', '')}.md`);

  // Dry run - just report what would happen
  if (options.dryRun) {
    console.log(`  [DRY RUN] Would convert ${pdfPaths.length} PDF(s) and combine to: ${combinedOutput}`);
    return { success: true, markdownPath: combinedOutput };
  }

  // Check if combined output already exists (skip if --force-convert)
  if (fs.existsSync(combinedOutput) && !options.forceConvert) {
    console.log(`  âœ… Using existing combined markdown: ${combinedOutput}`);
    return { success: true, markdownPath: combinedOutput };
  }

  if (options.forceConvert && fs.existsSync(combinedOutput)) {
    console.log(`  ğŸ”„ Force reconverting (--force-convert)`);
  }

  // Ensure learnings directory exists
  if (!fs.existsSync(LEARNINGS_DIR)) {
    fs.mkdirSync(LEARNINGS_DIR, { recursive: true });
  }

  // Check for pdftotext
  if (!checkPdftotext()) {
    console.error('  âŒ pdftotext not found. Install poppler: brew install poppler');
    return { success: false };
  }

  // Look for existing individual conversions first (unless force-convert)
  const markdownContents: string[] = [];
  const needsConversion: string[] = [];

  if (!options.forceConvert) {
    console.log('  ğŸ“ Looking for existing conversions...');
    for (const pdfPath of pdfPaths) {
      const baseName = path.basename(pdfPath, '.pdf');
      const possibleMds = [
        path.join(LEARNINGS_DIR, `${baseName}.md`),
        path.join(LEARNINGS_DIR, 'test-conversions', `${baseName}.md`),
      ];

      let found = false;
      for (const mdPath of possibleMds) {
        if (fs.existsSync(mdPath)) {
          console.log(`     âœ“ Found existing: ${path.basename(mdPath)}`);
          const content = fs.readFileSync(mdPath, 'utf-8');
          markdownContents.push(`# Source: ${path.basename(pdfPath)}\n\n${content}`);
          found = true;
          break;
        }
      }

      if (!found) {
        needsConversion.push(pdfPath);
      }
    }
  } else {
    // Force convert all
    needsConversion.push(...pdfPaths);
  }

  // Convert any PDFs that need conversion
  if (needsConversion.length > 0) {
    console.log(`\n  ğŸ”„ Converting ${needsConversion.length} PDF(s) to markdown...`);
    console.log('     (Using Claude Sonnet for conversion)\n');

    for (const pdfPath of needsConversion) {
      const pdfName = path.basename(pdfPath);
      try {
        // Extract text from PDF
        console.log(`  ğŸ“‘ Extracting text from ${pdfName}...`);
        const pdfText = extractPdfText(pdfPath);
        console.log(`     Extracted ${pdfText.length.toLocaleString()} characters`);

        // Convert to markdown via Claude
        const markdown = await convertPdfToMarkdown(pdfText, pdfName);
        console.log(`     Converted to ${markdown.length.toLocaleString()} characters of markdown`);

        markdownContents.push(`# Source: ${pdfName}\n\n${markdown}`);

        // Small delay between API calls
        if (needsConversion.indexOf(pdfPath) < needsConversion.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 2000));
        }
      } catch (error: any) {
        console.error(`  âŒ Failed to convert ${pdfName}: ${error.message}`);
        return { success: false };
      }
    }
  }

  if (markdownContents.length === 0) {
    console.log('  âŒ No markdown content generated');
    return { success: false };
  }

  // Combine and save
  if (markdownContents.length > 1) {
    console.log(`\n  ğŸ“ Combining ${markdownContents.length} markdown sources...`);
    const combined = markdownContents.join('\n\n---\n\n');
    fs.writeFileSync(combinedOutput, combined);
    console.log(`  âœ… Created combined markdown: ${combinedOutput}`);
  } else {
    // Single source - write directly to combined output
    fs.writeFileSync(combinedOutput, markdownContents[0]);
    console.log(`  âœ… Created markdown: ${combinedOutput}`);
  }

  return { success: true, markdownPath: combinedOutput };
}

/**
 * Step 2: Extract and validate topics
 */
async function stepExtractTopics(
  unitId: string,
  markdownPath: string,
  options: PipelineOptions
): Promise<{ success: boolean; topics?: string[] }> {
  console.log('\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
  console.log('â”‚  STEP 2: Topic Extraction & Validation                     â”‚');
  console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n');

  const existingUnit = units.find(u => u.id === unitId);

  if (options.skipTopics) {
    console.log('  â­ï¸  Skipping (--skip-topics)');
    if (existingUnit) {
      const topicNames = existingUnit.topics.map(t => t.name);
      console.log(`  â„¹ï¸  Using ${topicNames.length} existing topics from units.ts`);
      return { success: true, topics: topicNames };
    }
    console.log(`  âŒ Unit ${unitId} not found in units.ts`);
    return { success: false };
  }

  if (existingUnit && !options.reviewTopics) {
    const topicNames = existingUnit.topics.map(t => t.name);
    console.log(`  â„¹ï¸  Using ${topicNames.length} existing topics`);
    topicNames.forEach(t => console.log(`     â€¢ ${t}`));
    return { success: true, topics: topicNames };
  }

  // Run topic extraction
  console.log(`  ğŸ” Extracting topics from: ${path.basename(markdownPath)}`);

  if (options.dryRun) {
    console.log(`  [DRY RUN] Would run: npx tsx scripts/suggest-unit-topics.ts "${markdownPath}" ${unitId}`);
    return { success: true, topics: existingUnit?.topics.map(t => t.name) || [] };
  }

  const result = runScript('scripts/suggest-unit-topics.ts', [
    `"${markdownPath}"`,
    unitId,
  ], false);

  if (!result.success) {
    console.log(`  âŒ Topic extraction failed: ${result.error}`);
    return { success: false };
  }

  console.log(result.output);

  // After topic extraction, prompt for review if --review-topics specified
  if (options.reviewTopics) {
    console.log('\n  âš ï¸  Review the suggested topics above');
    console.log('     Update units.ts if needed, then continue');

    const proceed = await promptUser('\n  Continue with question generation?');
    if (!proceed) {
      console.log('  â¸ï¸  Paused for manual topic review');
      console.log('     Run again with --skip-topics after updating units.ts');
      return { success: false };
    }
  }

  // Re-read units.ts to get updated topics
  // Note: This won't work at runtime since units.ts is already imported
  // User should re-run the script after updating units.ts
  const updatedUnit = units.find(u => u.id === unitId);
  return { success: true, topics: updatedUnit?.topics.map(t => t.name) || [] };
}

/**
 * Step 2.5: Auto-update units.ts for new units
 * Only runs when the unit doesn't already exist in units.ts.
 */
async function stepAutoUpdateFiles(
  unitId: string,
  options: PipelineOptions
): Promise<{ success: boolean; topics?: string[] }> {
  console.log('\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
  console.log('â”‚  STEP 2.5: Auto-update Source Files (new unit)             â”‚');
  console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n');

  // Read the topic extraction output
  const topicsJsonPath = path.join(process.cwd(), 'data', `topics-${unitId}.json`);
  if (!fs.existsSync(topicsJsonPath)) {
    if (options.dryRun) {
      console.log(`  [DRY RUN] Would read ${topicsJsonPath} and auto-update:`);
      console.log('     - src/lib/units.ts (new unit entry with topic headings)');
      return { success: true, topics: [] };
    }
    console.log(`  âŒ Topic extraction output not found: ${topicsJsonPath}`);
    return { success: false };
  }

  const topicsData = JSON.parse(fs.readFileSync(topicsJsonPath, 'utf-8'));

  // Log any items that need review
  if (topicsData.reconciled?.needsReview?.length > 0) {
    console.log('  âš ï¸  Topics that may need manual review:');
    for (const item of topicsData.reconciled.needsReview) {
      console.log(`     ? "${item.extracted}" â€” ${item.reason}`);
    }
    console.log('     (Included in unit entry â€” edit units.ts after if needed)\n');
  }

  const suggestedTopics: string[] = topicsData.suggestedTopics || [];
  const suggestedLabel: string = topicsData.suggestedLabel || 'TODO: Add label';
  const headingMappings: Record<string, string[]> = topicsData.headingMappings || {};

  if (suggestedTopics.length === 0) {
    console.log('  âŒ No topics found in extraction output');
    return { success: false };
  }

  console.log(`  ğŸ“‹ ${suggestedTopics.length} topics to add`);
  console.log(`  ğŸ·ï¸  Label: "${suggestedLabel}"`);

  // Build topics with headings merged in
  const topicsWithHeadings = suggestedTopics.map(name => ({
    name,
    headings: headingMappings[name] || [],
  }));

  // --- Update units.ts ---
  const unitsPath = path.join(process.cwd(), 'src', 'lib', 'units.ts');
  const unitsContent = fs.readFileSync(unitsPath, 'utf-8');

  const unitNum = unitId.replace('unit-', '');
  const unitData = {
    id: unitId,
    title: `ğŸ‡«ğŸ‡· Unit ${unitNum}`,
    label: suggestedLabel,
    description: `Unit ${unitNum} content`,
    topics: topicsWithHeadings,
  };

  const updatedUnits = insertUnitEntry(unitsContent, unitData);

  if (updatedUnits) {
    if (options.dryRun) {
      console.log(`\n  [DRY RUN] Would update src/lib/units.ts with ${suggestedTopics.length} topics`);
    } else {
      fs.writeFileSync(unitsPath, updatedUnits);
      console.log(`  âœ… Updated src/lib/units.ts â€” added ${unitId}`);
    }
  } else {
    console.log(`  â„¹ï¸  Unit ${unitId} already in units.ts (skipped)`);
  }

  // Clean up temp JSON
  if (!options.dryRun) {
    fs.unlinkSync(topicsJsonPath);
    console.log(`  ğŸ§¹ Cleaned up ${topicsJsonPath}`);
  }

  return { success: true, topics: suggestedTopics };
}

/**
 * Step 3: Generate questions
 */
async function stepGenerateQuestions(
  unitId: string,
  topics: string[],
  options: PipelineOptions
): Promise<{ success: boolean; count?: number }> {
  console.log('\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
  console.log('â”‚  STEP 3: Question Generation                               â”‚');
  console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n');

  console.log(`  ğŸ“š Generating questions for ${topics.length} topics`);
  console.log(`  ğŸ¯ Unit: ${unitId}`);

  const args = ['--unit', unitId];
  if (options.syncDb) {
    args.push('--write-db');
  }
  if (options.dryRun) {
    args.push('--dry-run');
  }

  console.log(`  ğŸš€ Running: npx tsx scripts/generate-questions.ts ${args.join(' ')}\n`);

  if (options.dryRun) {
    const estimate = topics.length * 3 * 10;
    console.log(`  [DRY RUN] Would generate ~${estimate} questions`);
    return { success: true, count: estimate };
  }

  // Use spawn to stream output in real-time
  return new Promise((resolve) => {
    const proc = spawn('npx', ['tsx', 'scripts/generate-questions.ts', ...args], {
      stdio: 'inherit',
      shell: true,
    });

    proc.on('close', (code) => {
      if (code === 0) {
        resolve({ success: true });
      } else {
        resolve({ success: false });
      }
    });

    proc.on('error', (err) => {
      console.error(`  âŒ Error: ${err.message}`);
      resolve({ success: false });
    });
  });
}

/**
 * Step 4: Quality audit (optional, --audit flag)
 * Audits pending questions and promotes them to active/flagged.
 */
async function stepAuditQuestions(
  unitId: string,
  options: PipelineOptions
): Promise<{ success: boolean }> {
  console.log('\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
  console.log('â”‚  STEP 4: Quality Audit (pending â†’ active/flagged)          â”‚');
  console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n');

  const args = ['--write-db', '--pending-only', '--unit', unitId];

  console.log(`  ğŸ” Auditing pending questions for ${unitId}`);
  console.log(`  ğŸš€ Running: npx tsx scripts/audit-quality.ts ${args.join(' ')}\n`);

  if (options.dryRun) {
    console.log('  [DRY RUN] Would audit pending questions and promote to active/flagged');
    return { success: true };
  }

  return new Promise((resolve) => {
    const proc = spawn('npx', ['tsx', 'scripts/audit-quality.ts', ...args], {
      stdio: 'inherit',
      shell: true,
    });

    proc.on('close', (code) => {
      if (code === 0) {
        resolve({ success: true });
      } else {
        resolve({ success: false });
      }
    });

    proc.on('error', (err) => {
      console.error(`  âŒ Audit error: ${err.message}`);
      resolve({ success: false });
    });
  });
}

/**
 * Run the pipeline for a single unit
 */
async function runPipelineForUnit(
  unitId: string,
  options: PipelineOptions
): Promise<void> {
  console.log(`\n${'â•'.repeat(65)}`);
  console.log(`  PROCESSING: ${unitId.toUpperCase()}`);
  console.log(`${'â•'.repeat(65)}`);

  // Step 1: Convert PDF
  const step1 = await stepConvertPdf(unitId, options);
  if (!step1.success || !step1.markdownPath) {
    console.log('\n  âŒ Pipeline stopped: No markdown available');
    return;
  }

  // Step 2: Extract topics
  const step2 = await stepExtractTopics(unitId, step1.markdownPath, options);
  if (!step2.success) {
    console.log('\n  âŒ Pipeline stopped at topic extraction');
    return;
  }

  // Step 2.5: Auto-update source files (only for new units)
  let topics = step2.topics || [];
  const existingUnit = units.find(u => u.id === unitId);
  if (!existingUnit) {
    const step2_5 = await stepAutoUpdateFiles(unitId, options);
    if (!step2_5.success) {
      console.log('\n  âŒ Pipeline stopped at source file update');
      return;
    }
    topics = step2_5.topics || topics;
  }

  // Step 3: Generate questions
  const step3 = await stepGenerateQuestions(unitId, topics, options);
  if (!step3.success) {
    console.log('\n  âŒ Question generation failed');
    return;
  }

  // Step 4: Quality audit (optional)
  if (options.audit) {
    const step4 = await stepAuditQuestions(unitId, options);
    if (!step4.success) {
      console.log('\n  âš ï¸  Quality audit failed (questions remain as pending)');
    }
  }

  console.log('\n  âœ… Pipeline complete for', unitId);
}

/**
 * Main function
 */
async function main() {
  const options = parseArgs();

  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              CONTENT REGENERATION PIPELINE                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
`);

  console.log('Configuration:');
  console.log(`  Unit(s):       ${options.unitId}`);
  console.log(`  Review topics: ${options.reviewTopics ? 'Yes (interactive)' : 'No (auto)'}`);
  console.log(`  Skip convert:  ${options.skipConvert ? 'Yes' : 'No'}`);
  console.log(`  Force convert: ${options.forceConvert ? 'Yes' : 'No'}`);
  console.log(`  Skip topics:   ${options.skipTopics ? 'Yes' : 'No'}`);
  console.log(`  Write to DB:   ${options.syncDb ? 'Yes' : 'No'}`);
  console.log(`  Audit:         ${options.audit ? 'Yes (pending â†’ active/flagged)' : 'No'}`);
  console.log(`  Dry run:       ${options.dryRun ? 'Yes' : 'No'}`);

  if (options.unitId === '--all') {
    // Process all units
    for (const unit of units) {
      await runPipelineForUnit(unit.id, options);
    }

    // Post-processing: cross-unit topic consolidation
    console.log('\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
    console.log('â”‚  POST: Cross-Unit Topic Consolidation                      â”‚');
    console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n');

    const consolidationResult = runScript('scripts/suggest-unit-topics.ts', ['--consolidate'], options.dryRun);
    if (consolidationResult.output) {
      console.log(consolidationResult.output);
    }
  } else {
    // Validate unit exists or is a valid new unit
    const existingUnit = units.find(u => u.id === options.unitId);
    if (!existingUnit && !options.unitId.match(/^unit-\d+$/)) {
      console.error(`\nâŒ Invalid unit ID: ${options.unitId}`);
      console.log('   Format: unit-N (e.g., unit-4)');
      console.log('   Existing units:', units.map(u => u.id).join(', '));
      process.exit(1);
    }

    await runPipelineForUnit(options.unitId, options);
  }

  console.log(`\n${'â•'.repeat(65)}`);
  console.log('  PIPELINE COMPLETE');
  console.log(`${'â•'.repeat(65)}\n`);
}

// Run
main().catch(console.error);
